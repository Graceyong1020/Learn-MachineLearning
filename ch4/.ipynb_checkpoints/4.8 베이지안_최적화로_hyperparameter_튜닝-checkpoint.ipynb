{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edcda56-5cfa-45d9-a85a-180c2bcb4743",
   "metadata": {},
   "source": [
    "[베이지안 최적화 개요와 HyperOpt 사용법]\n",
    "\n",
    "1. 최초에는 랜덤하게 하이퍼 파라미터들을 샘플링하여 성능 결과를 관측\n",
    "2. 관측된 값을 기반으로 대체 모델은 최적 함수를 예측 추정\n",
    "3. 획득 함수에서 다음으로 관측할 하이퍼 파라미터 추출\n",
    "4. 해당 하이퍼 파라미터로 관측된 값을 기반으로 대체 모델은 다시 최적 함수 예측 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30af33ed-2e17-4135-bafb-bd97873f2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.7\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "\n",
    "print(hyperopt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2167de4-f408-44cc-8080-6546a3b4c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hyperopt==0.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a6914f-62d1-4bbd-b2b1-a3b151dd01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 검색 공간 설정 \n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x 집합값과 -15 ~ 15까지 1간격을 가지는 입력 변수  y 집합값 설정.\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1),  'y': hp.quniform('y', -15, 15, 1) } \n",
    "\n",
    "# quniform: 검색 공간 범위 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d20f29a-70dd-4361-9155-0c1ddb8e1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <hyperopt.pyll.base.Apply at 0x1e6699eaa00>,\n",
       " 'y': <hyperopt.pyll.base.Apply at 0x1e6699ea610>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space #search_space: 입력 값 범위 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24a3c22-d45b-4b76-bb46-1b77721d8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 목적 함수 설정 \n",
    "\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 입력 변수값과 입력 변수 검색 범위를 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval # return {'loss': retval, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1752918c-e810-487f-a177-7c079ec0a44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 259.20trial/s, best loss: -224.0]\n",
      "best: {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "# 3. 베이지안 최적화로 최소값 찾아냄 \n",
    "\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5 # fmin: 베이지안 최적화. 5번만에 찾음 \n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0) # trials: 수행했던 입력값과 출력값 저장 \n",
    "              )\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f610ae4-4df4-4350-9c89-a64983eaaa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 494.09trial/s, best loss: -296.0]\n",
      "best: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20 \n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b595e061-6fb4-426b-bf0d-0fc9ba0cdd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0x1e66aa14400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_val #.result/.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0262720-c9d6-4941-8f81-5e8fa23ff10e",
   "metadata": {},
   "source": [
    "* HyperOpt 수행 시 적용된 입력 값들과 목적 함수 반환값 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "708a9902-48c2-4358-93a8-c25c78deb0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin( )에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값} 와 같은 딕셔너리임. \n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ecd54fe-7557-4489-82e4-71b545f2f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46da28b-d4d9-4adb-badc-a77819f958c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성. \n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성. \n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'],\n",
    "                         'y': trial_val.vals['y'],\n",
    "                          'losses': losses\n",
    "                         }\n",
    "                        )\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84603362-d898-459a-9434-e71af79079a8",
   "metadata": {},
   "source": [
    "[HyperOpt를 XGBoost 하이퍼 파라미터 튜닝에 적용]\n",
    "\n",
    "\n",
    "1. search space(입력값 범위)\n",
    "   - 여러개의 입력 변수들고 이들 값의 범위 지정\n",
    "   - hp.quniform(label,low,high,q): label로 지정된 입력 값 변수 검색 공간을 최소값 low에서 최대값 high까지 q의 간격을 가지고 설정\n",
    "   - hp.quniform(label,low,high): 최소값 low에서 최대값 high까지 정규 분포 형태의 검색 공간 설정\n",
    "   - hp.randinit(label, upper): 0부터 최대값 upper까지 random한 정수 값으로 검색 공간 설정\n",
    "   - hp.loguniform(label, low, high): exp(uniform(low,high)값을 반환하며, 반환 값의 log 변환 된 값은 정규 분포 형태를 가지는 검색 공간 설정\n",
    "2. 목적 함수: search space를 입력 받아 로직에 따라 loss값을 계산하고 이를 반환하는 함수. 반드시 dictonary 형태의 값을 반환하고 여기에 'loss':loss값 기재\n",
    "3. 목적 함수의 최소값을 찾는 함수\n",
    "   - 목적 함수를 실행하여 최소 반환값(loss)를 최적으로 찾아 내는 함수\n",
    "   - Bayesian 최적화 기법으로 입력 변수들의 search space상에서 정해진 횟수만큼 입력 변수들을 입력 하여 목적 함수의 반환값(loss)을 최적으로 찾아냄\n",
    "   - hyperopt는 이를 위해 fmin() 함수를 제공\n",
    "   - fmin() 함수의 인자로 목적함수, search space, 베이지안 최적화 기법유형, 최적화 시도횟수, 최적화 로그 기록 객체를 인자로 넣으줌. best = fmin(objective,\n",
    "     space=hp.uniform('x',-10,10), algo=tpe.suggest, max_evals=100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761ddcf8-8c10-4c27-81fc-8b0aa2182d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']= dataset.target\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,\n",
    "                                         test_size=0.2, random_state=156 )\n",
    "\n",
    "# 학습 데이터를 다시 학습과 검증 데이터로 분리 \n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train,\n",
    "                                         test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338de671-807e-4a9e-a0bd-75acfd33f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색. \n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c50fabd-db50-42cc-9e4e-5eb04f5bdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space값으로 입력된 모든 값은 실수형임. \n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함. \n",
    "# 정확도는 높은 수록 더 좋은 수치임. -1* 정확도를 곱해서 큰 정확도 값일 수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 n_estimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'], \n",
    "                            eval_metric='logloss')\n",
    "    \n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "        \n",
    "    # accuracy는 cv=3 개수만큼의 정확도 결과를 가지므로 이를 평균해서 반환하되 -1을 곱해줌. (값이 클수록 모델의 성능이 좋음)\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae43938-a21e-45a5-ab9d-0e01604c4508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:20<00:00,  2.47trial/s, best loss: -0.9670616939700244]\n",
      "best: {'colsample_bytree': 0.684441779397407, 'learning_rate': 0.1475201153968472, 'max_depth': 9.0, 'min_child_weight': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4ac4e22-7955-4ea1-bcca-00dd654aae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_bytree:0.68444, learning_rate:0.14752, max_depth:9, min_child_weight:2\n"
     ]
    }
   ],
   "source": [
    "print('colsample_bytree:{0}, learning_rate:{1}, max_depth:{2}, min_child_weight:{3}'.format(\n",
    "                        round(best['colsample_bytree'], 5), round(best['learning_rate'], 5),\n",
    "                        int(best['max_depth']), int(best['min_child_weight'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a95b7e-e0d7-4b48-b260-59acc4a03c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdd7430e-163b-4c1d-be3f-62ce3702c8a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m xgb_wrapper \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m5\u001b[39m), \n\u001b[0;32m      2\u001b[0m                             max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]), min_child_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      3\u001b[0m                             colsample_bytree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      4\u001b[0m                            )\n\u001b[0;32m      6\u001b[0m evals \u001b[38;5;241m=\u001b[39m [(X_tr, y_tr), (X_val, y_val)]\n\u001b[1;32m----> 7\u001b[0m \u001b[43mxgb_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m preds \u001b[38;5;241m=\u001b[39m xgb_wrapper\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m pred_proba \u001b[38;5;241m=\u001b[39m xgb_wrapper\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=round(best['learning_rate'], 5), \n",
    "                            max_depth=int(best['max_depth']), min_child_weight=int(best['min_child_weight']),\n",
    "                            colsample_bytree=round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss', \n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24732d85-6633-48fd-a551-cc48e50168d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.585235</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>-0.949503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.727186</td>\n",
       "      <td>0.105956</td>\n",
       "      <td>-0.962676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959945</td>\n",
       "      <td>0.154804</td>\n",
       "      <td>-0.958261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.950012</td>\n",
       "      <td>0.120686</td>\n",
       "      <td>-0.956068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.674336</td>\n",
       "      <td>0.142392</td>\n",
       "      <td>-0.960454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.863774</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>-0.956068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.957521</td>\n",
       "      <td>0.079111</td>\n",
       "      <td>-0.958290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.695018</td>\n",
       "      <td>0.095213</td>\n",
       "      <td>-0.962676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.684442</td>\n",
       "      <td>0.147520</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.592116</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>-0.951711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.614798</td>\n",
       "      <td>0.076255</td>\n",
       "      <td>-0.962661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.776738</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>-0.956068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.514772</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>-0.953875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949783</td>\n",
       "      <td>0.083983</td>\n",
       "      <td>-0.949489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926121</td>\n",
       "      <td>0.112477</td>\n",
       "      <td>-0.949489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.570990</td>\n",
       "      <td>0.064663</td>\n",
       "      <td>-0.956097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.884549</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>-0.953904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.548302</td>\n",
       "      <td>0.184028</td>\n",
       "      <td>-0.967047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.532501</td>\n",
       "      <td>0.091771</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801498</td>\n",
       "      <td>0.193006</td>\n",
       "      <td>-0.951682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648909</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>-0.956068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.636702</td>\n",
       "      <td>0.175426</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819257</td>\n",
       "      <td>0.161105</td>\n",
       "      <td>-0.951696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.197617</td>\n",
       "      <td>-0.960454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.731961</td>\n",
       "      <td>0.166789</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735392</td>\n",
       "      <td>0.163609</td>\n",
       "      <td>-0.953889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.701649</td>\n",
       "      <td>0.135358</td>\n",
       "      <td>-0.956082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.836319</td>\n",
       "      <td>0.147475</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.764207</td>\n",
       "      <td>0.122779</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.704731</td>\n",
       "      <td>0.171094</td>\n",
       "      <td>-0.964854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653042</td>\n",
       "      <td>0.148807</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.739228</td>\n",
       "      <td>0.125882</td>\n",
       "      <td>-0.967047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.788451</td>\n",
       "      <td>0.199804</td>\n",
       "      <td>-0.962647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.991147</td>\n",
       "      <td>0.155752</td>\n",
       "      <td>-0.956082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.170745</td>\n",
       "      <td>-0.964869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.670654</td>\n",
       "      <td>0.109851</td>\n",
       "      <td>-0.962676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.857428</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>-0.938524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.712265</td>\n",
       "      <td>0.138138</td>\n",
       "      <td>-0.962661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677811</td>\n",
       "      <td>0.184643</td>\n",
       "      <td>-0.953889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.751712</td>\n",
       "      <td>0.116214</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.613785</td>\n",
       "      <td>0.103169</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.576204</td>\n",
       "      <td>0.145753</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815581</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>-0.951696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>-0.956097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.758812</td>\n",
       "      <td>0.127683</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.778703</td>\n",
       "      <td>0.154732</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.869484</td>\n",
       "      <td>0.191249</td>\n",
       "      <td>-0.964854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901248</td>\n",
       "      <td>0.160172</td>\n",
       "      <td>-0.947281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.722642</td>\n",
       "      <td>0.176144</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  learning_rate    losses\n",
       "0        19.0               2.0          0.585235       0.033688 -0.949503\n",
       "1         5.0               2.0          0.727186       0.105956 -0.962676\n",
       "2         6.0               2.0          0.959945       0.154804 -0.958261\n",
       "3         6.0               2.0          0.950012       0.120686 -0.956068\n",
       "4        16.0               2.0          0.674336       0.142392 -0.960454\n",
       "5         8.0               2.0          0.863774       0.106579 -0.956068\n",
       "6        14.0               2.0          0.957521       0.079111 -0.958290\n",
       "7        19.0               2.0          0.695018       0.095213 -0.962676\n",
       "8         9.0               2.0          0.684442       0.147520 -0.967062\n",
       "9         8.0               1.0          0.592116       0.081179 -0.951711\n",
       "10        6.0               2.0          0.614798       0.076255 -0.962661\n",
       "11        7.0               2.0          0.776738       0.089624 -0.956068\n",
       "12        8.0               2.0          0.514772       0.092214 -0.953875\n",
       "13       19.0               1.0          0.949783       0.083983 -0.949489\n",
       "14       10.0               1.0          0.926121       0.112477 -0.949489\n",
       "15        6.0               2.0          0.570990       0.064663 -0.956097\n",
       "16        7.0               2.0          0.884549       0.042766 -0.953904\n",
       "17       18.0               2.0          0.548302       0.184028 -0.967047\n",
       "18        6.0               2.0          0.910278       0.133006 -0.960468\n",
       "19        9.0               2.0          0.532501       0.091771 -0.958275\n",
       "20       11.0               1.0          0.801498       0.193006 -0.951682\n",
       "21       13.0               1.0          0.648909       0.183508 -0.956068\n",
       "22       17.0               2.0          0.636702       0.175426 -0.960468\n",
       "23       12.0               1.0          0.819257       0.161105 -0.951696\n",
       "24       16.0               2.0          0.500250       0.197617 -0.960454\n",
       "25       15.0               2.0          0.731961       0.166789 -0.967062\n",
       "26       15.0               1.0          0.735392       0.163609 -0.953889\n",
       "27       12.0               2.0          0.701649       0.135358 -0.956082\n",
       "28       14.0               2.0          0.836319       0.147475 -0.960468\n",
       "29       10.0               2.0          0.764207       0.122779 -0.958275\n",
       "30       13.0               2.0          0.704731       0.171094 -0.964854\n",
       "31       11.0               1.0          0.653042       0.148807 -0.958275\n",
       "32       15.0               2.0          0.739228       0.125882 -0.967047\n",
       "33       17.0               2.0          0.788451       0.199804 -0.962647\n",
       "34       20.0               2.0          0.991147       0.155752 -0.956082\n",
       "35        9.0               2.0          0.618285       0.170745 -0.964869\n",
       "36       14.0               2.0          0.670654       0.109851 -0.962676\n",
       "37       11.0               2.0          0.857428       0.015057 -0.938524\n",
       "38       15.0               2.0          0.712265       0.138138 -0.962661\n",
       "39       10.0               1.0          0.677811       0.184643 -0.953889\n",
       "40        5.0               2.0          0.751712       0.116214 -0.958275\n",
       "41       20.0               2.0          0.613785       0.103169 -0.958275\n",
       "42        9.0               2.0          0.576204       0.145753 -0.958275\n",
       "43       16.0               1.0          0.815581       0.062203 -0.951696\n",
       "44       18.0               2.0          0.596317       0.101125 -0.956097\n",
       "45        7.0               2.0          0.758812       0.127683 -0.960468\n",
       "46       13.0               2.0          0.778703       0.154732 -0.967062\n",
       "47       13.0               2.0          0.869484       0.191249 -0.964854\n",
       "48       17.0               1.0          0.901248       0.160172 -0.947281\n",
       "49        8.0               2.0          0.722642       0.176144 -0.967062"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "result_df = pd.DataFrame({'max_depth': trial_val.vals['max_depth'],\n",
    "                          'min_child_weight': trial_val.vals['min_child_weight'],\n",
    "                          'colsample_bytree': trial_val.vals['colsample_bytree'],\n",
    "                          'learning_rate': trial_val.vals['learning_rate'],\n",
    "                          'losses': losses\n",
    "                         }\n",
    "                        )\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f8a9d-8497-413c-8f59-a75bdc122f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
